{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import tensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\choco\\Downloads\\titanic\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes=df.mode().loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log(df['Fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>LogFare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>2.110213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>4.280593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>2.188856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>3.990834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>2.202765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>2.639057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>3.196630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>Q</td>\n",
       "      <td>2.169054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  24.0      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare    Cabin Embarked   LogFare  \n",
       "0        0         A/5 21171   7.2500  B96 B98        S  2.110213  \n",
       "1        0          PC 17599  71.2833      C85        C  4.280593  \n",
       "2        0  STON/O2. 3101282   7.9250  B96 B98        S  2.188856  \n",
       "3        0            113803  53.1000     C123        S  3.990834  \n",
       "4        0            373450   8.0500  B96 B98        S  2.202765  \n",
       "..     ...               ...      ...      ...      ...       ...  \n",
       "886      0            211536  13.0000  B96 B98        S  2.639057  \n",
       "887      0            112053  30.0000      B42        S  3.433987  \n",
       "888      2        W./C. 6607  23.4500  B96 B98        S  3.196630  \n",
       "889      0            111369  30.0000     C148        C  3.433987  \n",
       "890      0            370376   7.7500  B96 B98        Q  2.169054  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex']=df['Sex'].map({\"male\":1,\"female\":0})\n",
    "df['Embarked']=df['Embarked'].map({\"S\":1,\"C\":2,\"Q\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_dep = tensor(df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.,  1.,  0.,  ...,  1.,  1.,  3.],\n",
       "        [38.,  1.,  0.,  ...,  0.,  2.,  1.],\n",
       "        [26.,  0.,  0.,  ...,  0.,  1.,  3.],\n",
       "        ...,\n",
       "        [24.,  1.,  2.,  ...,  0.,  1.,  3.],\n",
       "        [26.,  0.,  0.,  ...,  1.,  2.,  1.],\n",
       "        [32.,  0.,  0.,  ...,  1.,  3.,  3.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare','sex','Embarked','Pclass'] \n",
    "df[indep_cols] = df[indep_cols].astype(float)\n",
    "t_indep = tensor(df[indep_cols].values, dtype=torch.float)\n",
    "t_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 7])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0717, -0.2111, -0.0776, -0.1429,  0.4577, -0.3900, -0.2067])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(23)\n",
    "\n",
    "n_coeff = t_indep.shape[1]\n",
    "coeffs = torch.rand(n_coeff)-0.5\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val,indices=t_indep.max(dim=0)\n",
    "#t_indep = t_indep / val\n",
    "t_indep = (t_indep - t_indep.mean(dim=0)) / t_indep.std(dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.9508e-01, -9.8882e-01, -3.0434e-01, -3.1617e-01,  6.0224e-01,\n",
       "        -5.7168e-01,  7.3299e-01, -2.0570e-02, -5.4755e-01, -9.8101e-01,\n",
       "        -5.7347e-01, -1.5017e-01,  6.8377e-01, -2.7972e-01, -2.3794e-01,\n",
       "        -3.0983e-01, -1.4851e+00,  8.4485e-01, -6.3444e-01, -8.9502e-01,\n",
       "         6.8818e-01,  7.9050e-01, -1.4735e+00,  9.2894e-01, -1.0107e+00,\n",
       "        -1.2324e+00,  6.2530e-02, -8.0894e-02, -1.5199e+00,  6.6456e-01,\n",
       "         2.8548e-01, -1.0180e+00, -1.5177e+00,  6.4559e-01,  2.3870e-03,\n",
       "         6.0636e-01,  6.2455e-02,  6.7833e-01, -7.5525e-01, -1.0908e+00,\n",
       "        -5.9552e-01, -3.8714e-01,  5.0965e-02, -1.1602e+00, -1.4927e+00,\n",
       "         6.6203e-01, -8.4523e-01, -1.5177e+00, -4.7002e-01, -5.6222e-01,\n",
       "        -3.2941e-01,  6.8246e-01, -1.0593e+00, -4.2822e-01, -6.2464e-02,\n",
       "         9.5068e-01, -6.7374e-02,  3.7997e-02, -4.9952e-01, -6.6293e-01,\n",
       "         7.3325e-02, -2.0055e-01,  5.2129e-01, -1.6742e-01,  3.7244e-01,\n",
       "        -3.2558e-01, -1.1086e-01,  6.8745e-01, -1.2138e+00,  2.5856e-01,\n",
       "         8.3039e-01, -1.6477e+00,  6.1455e-01, -2.3284e-01,  3.4580e-01,\n",
       "         6.6326e-01,  6.6456e-01,  6.6203e-01,  6.6588e-01, -3.8685e-01,\n",
       "         6.5817e-01,  6.1293e-01, -1.5184e+00,  8.8823e-01, -4.5633e-02,\n",
       "        -1.0105e+00,  2.4231e-02,  6.6203e-01, -1.0602e+00,  6.6203e-01,\n",
       "         6.3485e-01,  6.8699e-01,  5.6107e-01,  1.3906e-01,  4.8545e-01,\n",
       "         6.6203e-01,  8.5089e-02,  1.6262e-01, -3.4280e-01,  5.0215e-01,\n",
       "        -3.1473e-01,  6.6456e-01,  7.5818e-01,  6.0358e-01,  2.1049e-01,\n",
       "         6.4282e-01, -2.7255e-01,  6.6658e-01,  5.8847e-01, -1.8650e+00,\n",
       "         7.7065e-01, -1.1279e+00,  6.7290e-01, -4.9167e-01, -9.5005e-01,\n",
       "         6.8038e-01, -8.1293e-01,  5.5954e-01, -4.2117e-02, -1.3219e+00,\n",
       "         2.3162e-01,  6.6203e-01, -1.2401e-01, -1.5890e-01,  5.7882e-01,\n",
       "        -1.2237e-01, -5.6019e-01,  6.7763e-01, -1.3367e+00,  5.6654e-01,\n",
       "         2.0486e-03,  7.0104e-01, -6.9137e-01, -4.2822e-01,  8.3942e-01,\n",
       "         2.1657e-01, -1.2924e-01,  6.3051e-01,  6.8762e-01,  2.2096e-01,\n",
       "        -1.1879e+00, -2.7968e-01, -5.7868e-01, -5.1511e-01,  8.9418e-01,\n",
       "         4.3800e-01,  6.4992e-01, -9.9050e-01,  4.8755e-01,  7.4702e-01,\n",
       "         7.0319e-01, -2.7838e-01,  4.9082e-01,  3.0050e-01,  6.7457e-01,\n",
       "         1.5040e-02, -1.4740e+00,  6.2941e-01,  6.5237e-01, -1.3651e+00,\n",
       "         3.6322e-01, -2.2611e-01,  6.5571e-01,  6.9041e-01, -2.9680e-01,\n",
       "         4.2326e-01, -1.6625e-01, -1.1574e+00,  9.9556e-01,  3.6754e-01,\n",
       "         7.5789e-01, -1.4960e+00, -5.0147e-01,  6.8038e-01,  1.8398e-01,\n",
       "         4.1016e-01, -1.6691e-01, -7.3143e-01,  8.1224e-01,  9.2174e-01,\n",
       "        -2.3226e+00,  2.1110e-01, -4.0287e-01,  3.3583e-01, -5.1704e-01,\n",
       "         9.0133e-01, -1.8028e+00,  8.7804e-01, -1.0284e+00,  5.9934e-01,\n",
       "        -1.5618e-01,  8.7203e-01, -4.5658e-01,  5.7440e-01, -6.9381e-01,\n",
       "        -1.0113e+00, -5.6019e-01,  4.6229e-01, -1.5177e+00, -1.1270e-01,\n",
       "         6.1836e-01, -1.3651e+00,  6.3547e-01, -5.4326e-02,  6.9464e-01,\n",
       "        -3.0705e-01,  3.3539e-01, -7.7838e-02, -1.4743e+00,  2.6953e-01,\n",
       "         6.7930e-01, -2.3916e-01,  6.8655e-01,  8.1224e-01, -7.5166e-01,\n",
       "        -1.0183e+00, -3.0978e-01,  4.5330e-01, -7.7462e-01,  8.4126e-01,\n",
       "         7.0551e-01,  8.2855e-01,  5.1528e-01,  6.6456e-01,  5.4836e-01,\n",
       "         6.5310e-01,  9.0104e-01,  6.9470e-01,  8.7746e-01, -1.1245e+00,\n",
       "        -3.8191e-01,  6.3940e-01,  6.4944e-01, -1.3387e+00,  8.7387e-01,\n",
       "        -2.8714e-01,  4.4780e-01, -3.1645e-01,  9.0104e-01,  8.0378e-01,\n",
       "        -1.1795e+00, -1.8028e+00,  8.4669e-01,  6.8880e-01,  2.9919e-02,\n",
       "        -9.0291e-01, -2.9640e-01, -3.2019e-01,  5.3576e-01,  3.9345e-01,\n",
       "         6.7568e-01, -6.4526e-01,  7.8564e-01,  3.4408e-01, -7.0605e-01,\n",
       "        -1.2151e+00, -7.3659e-01, -1.6845e-01, -1.0702e+00, -4.4713e-01,\n",
       "        -5.6019e-01, -3.7025e-01,  3.9384e-01,  1.3944e+00, -1.5177e+00,\n",
       "         8.0865e-01, -3.7833e-01,  4.6968e-01, -5.0071e-01, -2.6137e-01,\n",
       "         9.7009e-01,  9.8153e-01, -3.5759e-01,  1.9571e-01, -1.5177e+00,\n",
       "        -5.2413e-01, -4.0469e-01,  1.2341e+00, -1.5123e+00, -7.6893e-01,\n",
       "        -7.8303e-01,  6.4351e-01,  6.8359e-01,  6.8920e-01,  9.9515e-01,\n",
       "        -1.0147e-02,  6.0749e-01,  6.7543e-01,  7.4702e-01, -1.5069e+00,\n",
       "        -1.3322e-01, -9.2125e-01,  1.6736e-01, -3.0802e-01,  6.6456e-01,\n",
       "         3.7244e-01,  6.5173e-02, -4.8221e-01,  9.7241e-01, -1.1410e+00,\n",
       "        -1.5177e+00, -1.0935e+00,  1.0141e+00, -1.3329e+00,  6.6203e-01,\n",
       "         4.8121e-01, -7.8570e-01, -9.3648e-01, -7.8353e-02, -7.2121e-01,\n",
       "        -7.4370e-01, -1.4548e+00, -5.0815e-01,  6.4282e-01,  3.5564e-01,\n",
       "        -3.0317e-01, -4.0105e-01,  6.7162e-01, -4.6071e-01, -1.1886e+00,\n",
       "         6.8655e-01,  6.4826e-01, -1.3655e+00, -5.0196e-01, -1.3651e+00,\n",
       "        -8.8040e-01,  4.9389e-01, -1.7792e-01, -7.4908e-01, -7.4401e-01,\n",
       "        -2.0510e+00,  8.6523e-01,  5.6554e-01,  2.1317e-01, -3.9089e-01,\n",
       "         6.6456e-01,  6.4113e-01, -9.0635e-01,  5.4789e-01,  8.3654e-01,\n",
       "         5.7984e-01, -1.0656e+00,  8.2311e-01,  8.3942e-01,  7.7963e-01,\n",
       "        -1.1270e-01, -1.9966e-01, -5.8085e-01,  3.9633e-01,  5.5453e-01,\n",
       "         6.4945e-01,  9.5271e-01, -1.7633e-01,  3.5728e-01,  6.2530e-02,\n",
       "         6.1836e-01, -1.5538e-01, -1.8879e-01, -1.5199e+00, -1.5199e+00,\n",
       "        -1.7263e-01, -9.3385e-02, -1.1984e+00,  6.1951e-01, -8.4523e-01,\n",
       "         6.4307e-01, -1.1163e+00, -8.9509e-01, -1.5177e+00, -7.1715e-01,\n",
       "         7.5882e-02,  5.3097e-01,  6.8920e-01,  1.5324e-01, -9.8355e-01,\n",
       "        -9.3342e-01, -2.7100e-01, -1.3156e-01,  1.5733e-01,  6.9375e-01,\n",
       "        -9.8889e-01, -1.0673e+00,  6.2060e-01, -3.1314e-01,  6.6456e-01,\n",
       "         6.3086e-01, -6.0858e-01, -1.7792e-01, -5.5984e-01, -6.7731e-01,\n",
       "         3.2472e-01,  6.8253e-01,  2.5941e-01, -9.7485e-01, -5.8695e-01,\n",
       "         6.7710e-01, -3.3034e-01,  6.2839e-01,  8.7930e-01, -1.3070e-01,\n",
       "         5.8255e-01,  6.5116e-01, -4.9710e-01,  3.5713e-01, -2.8344e-01,\n",
       "         5.3236e-01,  5.2025e-01,  6.2053e-01,  6.8288e-01, -1.1245e+00,\n",
       "         6.6456e-01, -5.4434e-01, -1.6092e+00,  1.2341e+00,  5.5537e-01,\n",
       "        -2.9552e-01, -5.8346e-01, -2.7256e-01,  8.1224e-01, -5.6268e-01,\n",
       "         5.0965e-02, -5.4361e-01,  6.3773e-01, -6.8338e-01,  2.8128e-01,\n",
       "         6.7568e-01, -4.2279e-01, -1.8240e-01, -5.6019e-01,  6.1854e-01,\n",
       "         9.7044e-01, -5.8085e-01, -4.9888e-01,  7.1598e-01,  5.5241e-01,\n",
       "        -5.1325e-01, -1.0557e+00, -8.3510e-01, -1.3502e-01,  8.3582e-01,\n",
       "        -6.1278e-01,  6.6184e-01,  4.6968e-01, -1.3444e-01,  6.6101e-01,\n",
       "         7.4597e-01, -2.0540e-01,  9.3782e-01, -1.4039e+00,  8.2023e-01,\n",
       "         2.8954e-01,  3.4662e-01,  3.3968e-01, -1.2356e-01,  6.6203e-01,\n",
       "         2.3789e-02,  7.6933e-01, -2.5297e-01, -2.2499e-01, -5.6019e-01,\n",
       "         8.6173e-01,  6.0767e-01,  8.1402e-01,  7.1441e-01,  6.6203e-01,\n",
       "         6.0321e-01,  1.2341e+00,  8.1825e-01, -5.5977e-01, -1.3808e+00,\n",
       "         6.7568e-01,  5.7627e-01, -6.5170e-01, -7.2897e-01, -3.1124e-01,\n",
       "         8.9566e-01,  5.3236e-01,  4.6073e-01,  6.8178e-01, -3.2884e-01,\n",
       "        -6.5206e-01,  1.2341e+00,  5.2071e-01, -5.3064e-01,  3.6826e-03,\n",
       "        -1.1245e+00, -3.9288e-01,  1.7781e-01,  6.2941e-01,  3.6372e-01,\n",
       "         3.4662e-01,  6.9198e-01,  8.0392e-01,  3.3726e-02,  6.7833e-01,\n",
       "        -3.0546e-02, -1.0894e+00,  5.7705e-01, -6.0722e-01,  6.6623e-01,\n",
       "         6.9041e-01, -1.5014e+00, -1.5157e+00, -3.8933e-01, -9.2362e-02,\n",
       "         1.5630e-02, -4.5097e-01,  9.9218e-01,  4.9937e-01,  3.7841e-01,\n",
       "        -5.8737e-01,  6.6203e-01,  9.2837e-01, -1.0493e+00,  6.7135e-01,\n",
       "         8.3177e-01, -1.3803e-01, -7.1594e-01, -4.6627e-01,  6.2108e-01,\n",
       "        -1.7981e-01,  6.7543e-01,  6.2530e-02, -8.9619e-01,  6.2455e-02,\n",
       "        -6.4987e-01, -2.2499e-01,  6.8385e-01,  5.8255e-01,  3.8783e-01,\n",
       "        -3.7771e-01,  6.2455e-02, -1.8720e-01, -1.2415e+00, -3.3779e-01,\n",
       "        -3.1102e-01,  8.7804e-01, -8.1231e-01,  5.8265e-01, -8.4996e-01,\n",
       "        -3.6478e-01, -1.3599e+00, -1.3708e+00,  5.1302e-01, -1.5493e-01,\n",
       "         7.7774e-01, -3.7387e-01,  2.2244e-01,  1.9759e-01,  4.9779e-01,\n",
       "         1.7417e-02,  7.3166e-01, -5.6152e-01,  7.3401e-02, -2.8010e-01,\n",
       "         7.8564e-01, -9.5808e-01,  6.6494e-02, -4.9305e-01, -6.5688e-01,\n",
       "        -5.6019e-01,  5.7760e-01,  8.1793e-01,  6.6203e-01, -2.9552e-01,\n",
       "         1.2832e-01,  6.9174e-01, -8.3918e-01,  6.2455e-02,  6.2177e-01,\n",
       "         6.6733e-01, -6.0098e-01,  9.2783e-01, -1.5177e+00,  7.0551e-01,\n",
       "         6.0983e-01, -1.6705e-01, -3.4536e-01, -1.1796e+00,  6.2060e-01,\n",
       "        -5.2310e-01, -1.1549e+00,  5.8491e-01,  2.5426e-01,  3.8008e-02,\n",
       "        -2.8368e-01,  7.0014e-01, -2.6241e-01,  6.7290e-01,  6.6203e-01,\n",
       "         6.1814e-01, -1.0785e+00,  5.5067e-01, -1.7102e+00,  4.8584e-01,\n",
       "         1.5833e-01, -2.4359e-01,  8.5108e-01,  6.2530e-02, -5.8400e-02,\n",
       "        -6.9411e-01,  6.6456e-01,  9.2514e-01,  5.5332e-01,  3.1879e-01,\n",
       "         3.1630e-01,  6.3195e-01,  9.5611e-01, -1.2634e+00, -3.0664e-01,\n",
       "        -1.2373e+00,  6.7930e-01, -1.8028e+00, -5.6019e-01,  6.0224e-01,\n",
       "        -7.2537e-01,  2.4155e-01, -5.9172e-01, -6.3803e-01,  8.6300e-01,\n",
       "        -2.3828e-01,  6.0483e-01, -3.0827e-01,  6.8156e-01,  5.8447e-01,\n",
       "         7.6302e-01, -5.5469e-01, -1.0439e-01,  6.5369e-01, -5.5991e-01,\n",
       "         6.7040e-01,  5.3247e-01,  3.1533e-01,  1.4813e+00, -1.1521e+00,\n",
       "        -1.3444e-01,  6.2060e-01,  4.2086e-01, -1.0908e+00,  3.7670e-01,\n",
       "         6.8699e-01, -7.1715e-01, -1.1141e+00,  3.8928e-01, -1.3808e+00,\n",
       "        -9.6335e-02,  6.9174e-01,  1.6316e-01,  6.7041e-01, -2.8170e-01,\n",
       "         6.6456e-01, -2.5583e-01,  6.7221e-01, -1.5191e+00, -1.4672e+00,\n",
       "         2.1532e-01,  6.6456e-01, -1.9425e+00,  8.5029e-01, -2.0855e-01,\n",
       "         2.3387e-01, -2.4432e-02,  8.7241e-01,  6.0613e-01,  4.9435e-01,\n",
       "         1.7183e-01,  8.3942e-01,  6.6658e-01,  5.5876e-01, -2.5335e-01,\n",
       "        -6.4223e-01,  6.6615e-01,  6.2385e-01,  8.0680e-01,  1.2341e+00,\n",
       "         6.9919e-01,  6.5931e-01, -2.8956e-01, -1.4135e+00, -2.1434e-01,\n",
       "        -1.5241e+00,  2.0927e-01,  6.6576e-01, -6.7924e-01,  2.0662e-01,\n",
       "        -3.2220e-01, -3.6746e-01,  6.5814e-01,  6.9884e-01, -3.1394e-01,\n",
       "         6.5285e-01, -9.6534e-01,  3.8928e-01,  5.7095e-02,  7.9651e-01,\n",
       "         6.8749e-01,  5.5332e-01, -1.5175e+00, -2.5174e-01,  5.7086e-01,\n",
       "        -1.0499e+00,  9.3380e-01, -1.0517e+00, -5.6549e-01,  4.6292e-01,\n",
       "         6.6644e-01, -2.3201e-01,  8.9576e-01, -2.0697e-01, -3.2558e-01,\n",
       "        -6.6837e-01,  9.9218e-01,  5.7375e-01,  6.1316e-01,  6.9267e-01,\n",
       "         6.9587e-01, -9.6715e-01, -9.9985e-02, -6.5376e-01,  6.1766e-01,\n",
       "        -2.4199e-01,  5.2580e-01,  7.9050e-01,  7.0354e-01,  6.8486e-01,\n",
       "         6.7411e-01, -7.8638e-01, -1.5175e+00,  5.5107e-01, -4.9037e-01,\n",
       "        -2.9380e-01,  3.6895e-03,  1.2341e+00,  8.5029e-01,  8.5029e-01,\n",
       "         5.4370e-01, -1.1072e+00, -1.1267e-01,  6.6456e-01,  6.6456e-01,\n",
       "         9.7477e-01,  5.7851e-01, -1.4711e+00,  3.7670e-01,  6.2603e-01,\n",
       "         3.1274e-01,  2.9189e-01, -1.4531e-01,  7.2834e-01, -5.9824e-01,\n",
       "        -3.7121e-01,  6.0490e-01,  5.9119e-01,  6.7000e-01, -8.5582e-01,\n",
       "         6.6894e-01,  6.4449e-01,  8.9418e-01,  6.0767e-01, -1.8476e-01,\n",
       "         5.8265e-01,  5.8553e-01,  8.4196e-02, -6.3282e-01,  7.1006e-01,\n",
       "        -4.5891e-01,  3.2138e-01, -1.5531e+00, -9.0740e-01,  6.1354e-01,\n",
       "         6.4010e-01,  5.3481e-01, -2.6304e-01,  6.2530e-02, -8.3544e-01,\n",
       "         6.9961e-01, -5.6019e-01, -2.5097e-01, -5.5998e-01, -4.6613e-01,\n",
       "        -8.3531e-01, -2.2861e-01,  9.4760e-01,  1.3148e-01,  6.7386e-01,\n",
       "         6.7024e-01, -2.5359e-01, -1.5177e+00,  2.7494e-01,  1.0139e-01,\n",
       "        -5.6019e-01,  7.9145e-01, -2.3226e+00,  3.5790e-01,  6.5913e-01,\n",
       "         7.6332e-01, -9.7889e-02, -3.4355e-01,  2.9844e-02, -7.6661e-01,\n",
       "         7.9050e-01, -5.3669e-01,  4.6060e-01,  7.2936e-02,  6.6437e-01,\n",
       "         6.2853e-01,  1.3998e+00, -2.5836e-01,  7.6332e-01, -3.0530e-01,\n",
       "         6.5383e-01,  4.2973e-01,  8.1408e-01, -1.3436e+00,  6.2670e-01,\n",
       "         1.4813e+00, -2.8803e-01, -2.4181e-01,  5.8746e-01, -2.0003e-01,\n",
       "        -5.8708e-01,  6.3606e-01,  1.4052e+00, -4.6679e-01, -3.0224e-01,\n",
       "        -5.4605e-01,  3.8928e-01,  1.6475e-02, -5.6019e-01, -3.3099e-01,\n",
       "        -1.1306e+00,  6.3232e-01,  6.2455e-02,  6.7069e-01,  6.9062e-01,\n",
       "        -1.1129e+00,  6.6867e-01,  6.6203e-01,  3.4580e-01,  3.6261e-01,\n",
       "         6.8582e-01,  9.1735e-01, -6.3367e-01,  2.0307e-02,  6.9041e-01,\n",
       "         5.7258e-01, -1.3651e+00, -8.8218e-03,  5.9598e-01, -9.4523e-01,\n",
       "        -3.7518e-01,  3.9482e-01, -1.2016e+00, -7.4601e-02, -5.0975e-01,\n",
       "        -3.7895e-01, -6.3203e-01,  8.4543e-01, -1.3167e+00,  6.2455e-02,\n",
       "         1.1110e-01,  6.8641e-01, -9.2454e-02, -2.3226e+00,  8.4485e-01,\n",
       "        -2.1053e-01, -9.4284e-01,  8.6186e-01,  6.4010e-01,  4.3978e-01,\n",
       "         6.5369e-01, -4.7614e-01,  1.1681e+00,  5.2229e-01, -1.0250e+00,\n",
       "        -8.4610e-01,  6.5706e-01,  6.9174e-01,  6.6456e-01, -1.0139e+00,\n",
       "        -3.1125e-01,  6.1564e-01, -3.2021e-01,  8.5213e-01,  6.7386e-01,\n",
       "        -2.2628e+00,  8.2855e-01,  4.4400e-02, -8.2607e-01,  3.5031e-01,\n",
       "        -6.0367e-01])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8992)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs(preds-t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pred(coeffs, indeps): return torch.sigmoid((indeps@coeffs).sum(axis=1))\n",
    "def cal_loss(q,t_indep,t_dep): return torch.abs(cal_pred(q,t_indep)-t_dep).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 179)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and validation sets\n",
    "trn_indep, val_indep, trn_dep, val_dep = train_test_split(t_indep, t_dep, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the length of training and validation sets\n",
    "len(trn_indep), len(val_indep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff, 1)*0.1).requires_grad_()\n",
    "\n",
    "def update_coeffs(coeffs, lr):\n",
    "    coeffs.sub_(coeffs.grad * lr)\n",
    "    coeffs.grad.zero_()\n",
    "def one_epoch(coeffs, lr):\n",
    "    loss = cal_loss(coeffs, trn_indep, trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, lr=0.01):\n",
    "    torch.manual_seed(442)\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(coeffs): return (val_dep.bool()==(cal_pred(coeffs, val_indep)>0.5)).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712; 13.085; 12.666; 11.233; 9.634; 7.868; 6.047; 3.053; 2.607; 21.923; 20.944; 17.878; 17.526; 17.405; 17.161; 17.392; 16.585; 16.612; 16.222; 15.961; 15.021; 14.501; 13.374; 12.103; 10.254; 9.619; 7.906; 6.424; 4.195; 2.630; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7542)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_hidden=20):\n",
    "    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden\n",
    "    layer2 = torch.rand(n_hidden, 1)-0.3\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def cal_pred(coeffs, indeps):\n",
    "    l1,l2,const = coeffs\n",
    "    res = F.relu(indeps@l1)\n",
    "    res = res@l2 + const\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    for layer in coeffs:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778; 0.737; 0.706; 0.680; 0.657; 0.637; 0.619; 0.602; 0.587; 0.572; 0.559; 0.546; 0.535; 0.524; 0.515; 0.506; 0.498; 0.491; 0.484; 0.479; 0.474; 0.469; 0.466; 0.462; 0.459; 0.457; 0.454; 0.452; 0.451; 0.449; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7821)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712; 0.653; 0.613; 0.585; 0.565; 0.550; 0.538; 0.528; 0.521; 0.514; 0.509; 0.505; 0.501; 0.498; 0.496; 0.494; 0.492; 0.490; 0.488; 0.487; 0.486; 0.485; 0.484; 0.483; 0.483; 0.482; 0.482; 0.481; 0.481; 0.480; 0.480; 0.480; 0.479; 0.479; 0.479; 0.479; 0.478; 0.478; 0.478; 0.478; 0.478; 0.478; 0.478; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.477; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; 0.476; \n",
      "Accuracy: 79.33%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    hiddens = [10, 10]  # <-- set this to the size of each hidden layer you want\n",
    "    sizes = [n_coeff] + hiddens + [1]\n",
    "    n = len(sizes)\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "    return layers,consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def cal_pred(coeffs, indeps):\n",
    "    layers,consts = coeffs\n",
    "    n = len(layers)\n",
    "    res = indeps\n",
    "    for i,l in enumerate(layers):\n",
    "        res = res@l + consts[i]\n",
    "        if i!=n-1: res = F.relu(res)\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    layers,consts = coeffs\n",
    "    for layer in layers+consts:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.688; 0.660; 0.646; 0.626; 0.595; 0.544; 0.508; 0.485; 0.471; 0.461; 0.454; 0.449; 0.445; 0.442; 0.440; 0.438; 0.436; 0.435; 0.434; 0.433; 0.432; 0.431; 0.431; 0.430; 0.429; 0.429; 0.428; 0.428; 0.427; 0.427; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7709)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
